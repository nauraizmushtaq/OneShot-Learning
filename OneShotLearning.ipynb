{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project_Deep_V2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "uDnPNfc736kY",
        "rudyUDtd4CpV"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "krhpW3YEIi2d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "76c9727e-55c0-4bdb-b066-cf5458580671"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDnPNfc736kY",
        "colab_type": "text"
      },
      "source": [
        "### 1. Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aW9_nNq9m2We",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import os\n",
        "from numpy.random import choice as npc\n",
        "import numpy as np\n",
        "import time\n",
        "import random\n",
        "import torchvision.datasets as dset\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import torchvision.datasets as dset\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "from collections import deque"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rudyUDtd4CpV",
        "colab_type": "text"
      },
      "source": [
        "### 2. Build Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6oucMO2QScr",
        "colab_type": "code",
        "outputId": "41315b7e-f076-474a-f011-9507c613db66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "class Network(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.buildNetwork()\n",
        "\n",
        "\n",
        "    def buildNetwork(self):\n",
        "        \"\"\"\n",
        "            Declare layes of the networks\n",
        "        \"\"\"\n",
        "        self.convLayers = nn.Sequential(\n",
        "          nn.Conv2d(in_channels= 1, out_channels= 64, kernel_size=10),\n",
        "          nn.ReLU(inplace=True),\n",
        "          nn.MaxPool2d(2), \n",
        "          nn.Conv2d(in_channels=64, out_channels=128, kernel_size=7), \n",
        "          nn.ReLU(),              \n",
        "          nn.MaxPool2d(2),\n",
        "          nn.Conv2d(in_channels=128, out_channels=128, kernel_size=4),\n",
        "          nn.ReLU(), \n",
        "          nn.MaxPool2d(2),\n",
        "          nn.Conv2d(in_channels=128, out_channels=256, kernel_size=4),\n",
        "          nn.ReLU() \n",
        "        )\n",
        "        self.linearLayers = nn.Sequential(\n",
        "            nn.Linear(9216, 4096),\n",
        "            nn.Sigmoid())\n",
        "        self.outLayer = nn.Linear(4096, 1)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self,x1,x2):\n",
        "        \"\"\"\n",
        "            x1, x2 : Two input images \n",
        "        \"\"\"\n",
        "\n",
        "        # Perform two forward pass from convolution layer for each input images\n",
        "        x1_out = self.convLayers(x1)\n",
        "        x2_out = self.convLayers(x2)\n",
        "        \n",
        "        # Resize both outputs for linear layers\n",
        "        x1_out = x1_out.view(x1_out.size()[0], -1)\n",
        "        x2_out = x2_out.view(x2_out.size()[0], -1)\n",
        "        \n",
        "        x1_out = self.linearLayers(x1_out)\n",
        "        x2_out = self.linearLayers(x2_out)\n",
        "\n",
        "        # Take absolute distance for both outputs\n",
        "        distance = torch.abs(x1_out - x2_out)\n",
        "        output = self.outLayer(distance)\n",
        "        \n",
        "        return output\n",
        "\n",
        "test = Network()\n",
        "print(test)\n",
        "  "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Network(\n",
            "  (convLayers): Sequential(\n",
            "    (0): Conv2d(1, 64, kernel_size=(10, 10), stride=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(64, 128, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (4): ReLU()\n",
            "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(128, 128, kernel_size=(4, 4), stride=(1, 1))\n",
            "    (7): ReLU()\n",
            "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (9): Conv2d(128, 256, kernel_size=(4, 4), stride=(1, 1))\n",
            "    (10): ReLU()\n",
            "  )\n",
            "  (linearLayers): Sequential(\n",
            "    (0): Linear(in_features=9216, out_features=4096, bias=True)\n",
            "    (1): Sigmoid()\n",
            "  )\n",
            "  (outLayer): Linear(in_features=4096, out_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfM43Ksl4KVP",
        "colab_type": "text"
      },
      "source": [
        "### 3. Import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgrfOGaAUx4a",
        "colab_type": "code",
        "outputId": "4bacc96e-98a1-4fe4-aae7-7f7e8f63fcce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "%%shell\n",
        "git clone https://github.com/brendenlake/omniglot.git\n",
        "cd omniglot/python\n",
        "unzip -q images_evaluation.zip\n",
        "unzip -q images_background.zip\n",
        "cd ../..\n",
        "# setup directory for saving models\n",
        "mkdir models"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'omniglot'...\n",
            "remote: Enumerating objects: 81, done.\u001b[K\n",
            "remote: Total 81 (delta 0), reused 0 (delta 0), pack-reused 81\u001b[K\n",
            "Unpacking objects: 100% (81/81), done.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OO9g8KTE4by8",
        "colab_type": "text"
      },
      "source": [
        "### 4. Dataset Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KICuREYvXEKV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataSet(Dataset):\n",
        "\n",
        "    def __init__(self, train=True ,times=200 ,batch_size=20, transform=None):\n",
        "        super().__init__()\n",
        "        self.train= train\n",
        "        self.transform = transform\n",
        "        self.times = times\n",
        "        self.batch_size = batch_size\n",
        "        self.img1 = None\n",
        "        self.c1 = None\n",
        "        self.datas = {}\n",
        "        self.num_classes = 0\n",
        "        self.train_dataPath = \"./omniglot/python/images_background\"\n",
        "        self.test_dataPath = \"./omniglot/python/images_evaluation\"\n",
        "        if self.train:\n",
        "          self.loadTrainData()\n",
        "        else:\n",
        "          self.loadTestData()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "          Returns count of total instances\n",
        "        \"\"\"\n",
        "        if self.train:\n",
        "            return 21000000\n",
        "        else:\n",
        "            return self.times * self.batch_size\n",
        "\n",
        "\n",
        "\n",
        "    def loadTrainData(self):\n",
        "      \"\"\"\n",
        "          Loads training dataset from self.train_dataPath \n",
        "          Counts the number of classes\n",
        "          Maintains images wrt classes in dictonary\n",
        "      \"\"\"\n",
        "\n",
        "      classesConut = 0\n",
        "      annotationAngels  = [0, 90, 180, 270]\n",
        "      for i in annotationAngels:\n",
        "        for j in os.listdir(self.train_dataPath):\n",
        "            for k in os.listdir(os.path.join(self.train_dataPath, j)):\n",
        "                self.datas[classesConut] = []\n",
        "                for m in os.listdir(os.path.join(self.train_dataPath, j, k)):\n",
        "                    filePath = os.path.join(self.train_dataPath, j, k, m)\n",
        "                    # Rotate grayscale images along angles and store in dictionary\n",
        "                    self.datas[classesConut].append(Image.open(filePath).rotate(i).convert('L'))\n",
        "                classesConut += 1\n",
        "      print(\"Train Data Loaded\")\n",
        "      self.num_classes =  classesConut\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def getTrainImages(self,index):\n",
        "        \"\"\"\n",
        "          Gets training images at 'index'\n",
        "          Return : two images and label\n",
        "        \"\"\"\n",
        "        label = None\n",
        "        if index % 2 == 1:      # Same images \n",
        "            label = 1.0\n",
        "            randomIndexA = random.randint(0, self.num_classes - 1)\n",
        "            image1 = random.choice(self.datas[randomIndexA])\n",
        "            image2 = random.choice(self.datas[randomIndexA])\n",
        "        else:\n",
        "            label = 0.0         # Different images\n",
        "            randomIndexA = random.randint(0, self.num_classes - 1)\n",
        "            randomIndexB = random.randint(0, self.num_classes - 1)\n",
        "            # While both random int are equal repeat\n",
        "            while randomIndexA == randomIndexB:\n",
        "                randomIndexB = random.randint(0, self.num_classes - 1)\n",
        "            image1 = random.choice(self.datas[randomIndexA])\n",
        "            image2 = random.choice(self.datas[randomIndexB])\n",
        "\n",
        "        # Apply transfrom on images if any\n",
        "        if self.transform:\n",
        "            image1 = self.transform(image1)\n",
        "            image2 = self.transform(image2)\n",
        "        return image1,image2,label\n",
        "\n",
        "\n",
        "\n",
        "    def __getitem__(self,index):\n",
        "        \"\"\"\n",
        "          Returns items at index\n",
        "        \"\"\"\n",
        "        if self.train:\n",
        "            image1,image2,label = self.getTrainImages(index)\n",
        "            return image1, image2, torch.from_numpy(np.array([label], dtype=np.float32))\n",
        "        else:\n",
        "\n",
        "            img1,img2 = self.getTestImages(index)\n",
        "            return img1, img2\n",
        "\n",
        "\n",
        "\n",
        "    def getTestImages(self,index):\n",
        "      \"\"\"\n",
        "          Gets testing images at 'index'\n",
        "          Return : two images\n",
        "      \"\"\"\n",
        "      randomIndex = index % self.batch_size\n",
        "      label = None\n",
        "      if randomIndex == 0:\n",
        "          self.c1 = random.randint(0, self.num_classes - 1)\n",
        "          self.img1 = random.choice(self.datas[self.c1])\n",
        "          img2 = random.choice(self.datas[self.c1])\n",
        "      else:\n",
        "          randomClass = random.randint(0, self.num_classes - 1)\n",
        "          while self.c1 == randomClass:\n",
        "              randomClass = random.randint(0, self.num_classes - 1)\n",
        "          img2 = random.choice(self.datas[randomClass])\n",
        "      if self.transform:\n",
        "          img1 = self.transform(self.img1)\n",
        "          img2 = self.transform(img2)\n",
        "      return img1,img2\n",
        "\n",
        "\n",
        "\n",
        "    def loadTestData(self):\n",
        "      \"\"\"\n",
        "          Loads testing dataset from self.test_dataPath \n",
        "          Counts the number of classes\n",
        "          Maintains images wrt classes in dictonary\n",
        "      \"\"\"\n",
        "      \n",
        "      classCount = 0\n",
        "      for i in os.listdir(self.test_dataPath):\n",
        "        for j in os.listdir(os.path.join(self.test_dataPath, i)):\n",
        "            self.datas[classCount] = []\n",
        "            for k in os.listdir(os.path.join(self.test_dataPath, i, j)):\n",
        "                filePath = os.path.join(self.test_dataPath, i, j, k)\n",
        "                self.datas[classCount].append(Image.open(filePath).convert('L'))\n",
        "            classCount += 1\n",
        "      print(\"Test Data Loaded\")\n",
        "      self.num_classes =  classCount\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHeZKvca7iDQ",
        "colab_type": "text"
      },
      "source": [
        "### Execution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pISsp_IzgqRh",
        "colab_type": "code",
        "outputId": "8fc0af1e-6058-4acd-ae64-040c06711211",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "class OneShotLearner():\n",
        "  def __init__(self):\n",
        "    self.transformations = transforms.Compose([\n",
        "        transforms.RandomAffine(15),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "    self.workers = 4                  # Number of dataloader workers\n",
        "    self.batch_size = 128             # Training Batch size\n",
        "    self.test_batch_size = 20         # Testing Batch size\n",
        "    self.times = 400\n",
        "    self.CUDA = True\n",
        "    self.learning_rate = 0.1\n",
        "    self.max_iterations = 35000\n",
        "    self.model_path = 'models'        # Path to save weights\n",
        "    self.train_dataset = DataSet(train=True,transform=self.transformations)\n",
        "    self.train_loader = DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=False, num_workers=self.workers)\n",
        "    self.test_dataset = DataSet( train=False, transform=transforms.ToTensor(), times=self.times, batch_size=self.test_batch_size)\n",
        "    self.test_loader = DataLoader(self.test_dataset, batch_size=self.test_batch_size, shuffle=False, num_workers=self.workers)\n",
        "    self.model = Network()\n",
        "    self.cudaTrainSetting()\n",
        "    self.loss_fn = torch.nn.BCEWithLogitsLoss(size_average=True)\n",
        "\n",
        "    \n",
        "  def cudaTrainSetting(self):\n",
        "    if self.CUDA:\n",
        "      self.model.cuda()\n",
        "    self.model.train()\n",
        "\n",
        "  def load_weights(self, PATH):\n",
        "    self.model.load_state_dict(torch.load(PATH))\n",
        "    self.model.eval()\n",
        "\n",
        "  def train(self):\n",
        "    optimizer = torch.optim.SGD(self.model.parameters(),lr = self.learning_rate )\n",
        "    optimizer.zero_grad()\n",
        "    train_loss = []\n",
        "    loss_val = 0\n",
        "    time_start = time.time()\n",
        "\n",
        "    for batch_id, (img1, img2, label) in enumerate(self.train_loader, 1):\n",
        "        if batch_id > self.max_iterations:\n",
        "            break\n",
        "        if self.CUDA:\n",
        "            img1, img2, label = Variable(img1.cuda()), Variable(img2.cuda()), Variable(label.cuda())\n",
        "        else:\n",
        "            img1, img2, label = Variable(img1), Variable(img2), Variable(label)\n",
        "        optimizer.zero_grad()\n",
        "        output = self.model.forward(img1, img2)     # Forward Pass\n",
        "        loss = self.loss_fn(output, label)          # Calculate loss \n",
        "        loss_val += loss.item()\n",
        "        loss.backward()                             # BackPropogation\n",
        "        optimizer.step()                            # Update weights\n",
        "\n",
        "        # Display loss\n",
        "        if batch_id % 10 == 0:\n",
        "            print('Batch Id=> %d\\tloss=>\\t%.5f\\ttime lapsed=>\\t%.2f s'%(batch_id, loss_val/10, time.time() - time_start))\n",
        "            loss_val = 0\n",
        "            time_start = time.time()\n",
        "\n",
        "        # Save weights\n",
        "        if batch_id % 200 == 0:\n",
        "            self.predict(batch_id)\n",
        "            torch.save(self.model.state_dict(), self.model_path + '/model-inter-' + str(batch_id+1) + \".pt\")\n",
        "        train_loss.append(loss_val)\n",
        "  \n",
        "  \n",
        "  def predict(self,batch_id):        \n",
        "    right, error = 0, 0\n",
        "    for _, (test1, test2) in enumerate(self.test_loader, 1):\n",
        "        if self.CUDA:\n",
        "            test1, test2 = test1.cuda(), test2.cuda()\n",
        "        test1, test2 = Variable(test1), Variable(test2)\n",
        "        output = self.model.forward(test1, test2).data.cpu().numpy()\n",
        "        pred = np.argmax(output)\n",
        "        if pred == 0:\n",
        "            right += 1\n",
        "        else: \n",
        "            error += 1\n",
        "    print('-'*100)\n",
        "    print('Batch Id=> %d\\tcorrect=>\\t%d\\terror=>\\t%d\\tprecision=>\\t%f'%(batch_id, right, error, right*1.0/(right+error)))\n",
        "    print('-'*100)\n",
        "\n",
        "\"\"\"\n",
        "  Execute training\n",
        "\"\"\"\n",
        "\n",
        "test = OneShotLearner()\n",
        "test.train()\n",
        "\n",
        "#PATH = 'drive/My Drive/Deep_Project/model-inter-35001.pt'\n",
        "#test.load_weights(PATH)\n",
        "test.predict(1)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Data Loaded\n",
            "Test Data Loaded\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------------------------------------------\n",
            "Batch Id=> 1\tcorrect=>\t382\terror=>\t18\tprecision=>\t0.955000\n",
            "----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sb6FMhezfhn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test.times = 9000\n",
        "test.test_dataset = DataSet( train=False, transform=transforms.ToTensor(), times=test.times, batch_size=test.test_batch_size)\n",
        "test.test_loader = DataLoader(test.test_dataset, batch_size=test.test_batch_size, shuffle=False, num_workers=test.workers)      \n",
        "test.predict(100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32QRdjfdqO84",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"final accuracy: \", acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsjS-gR0BVlE",
        "colab_type": "text"
      },
      "source": [
        "### Team\n",
        "1. Muhammad Nuaraiz Mushtaq  - 160106\n",
        "2. Govinda Kumar             - 160249\n",
        "3. Abid Waqar                - 160229\n",
        "4. Ahsan Abbas               - 160101"
      ]
    }
  ]
}